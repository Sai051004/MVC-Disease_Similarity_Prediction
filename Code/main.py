import argparse
import numpy as np
import torch
import torch.optim as optim
from torch_geometric.data import Data
from utils import (
    load_sparse,
    mx_to_torch_sparse_tensor,
    generate_sparse_one_hot,
    plot_roc_curve,
    plot_precision_recall,
    plot_auc_vs_feature_dimensionality,
    plot_true_positive_pairs,
    plot_auc_vs_epochs,
    plot_auc_vs_weighting_coefficient,
)
from model import AGCN, GAT, Projection_dis_gene, Projection_dis_miRNA, Attention_dis, Dis_score, MVC
from trainer import CrossValidationTrainer
from explainability import compute_pair_contributions
import csv
import os
import matplotlib.pyplot as plt

# Pooling function for evaluation
def pooling(x, y2x):
    x = torch.mm(y2x, x)
    row_sum = torch.sum(y2x, dim=1).clamp(min=1e-8).reshape(-1, 1)
    return torch.div(x, row_sum)

# Data augmentation functions
def augment_features(x, noise_std=0.01, dropout_rate=0.05):
    """Apply feature-level augmentation"""
    if noise_std > 0:
        noise = torch.randn_like(x) * noise_std
        x = x + noise
    
    if dropout_rate > 0 and x.requires_grad:
        mask = torch.rand_like(x) > dropout_rate
        x = x * mask.float()
    
    return x

def mixup_features(x1, x2, alpha=0.2):
    """Apply mixup augmentation"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    return lam * x1 + (1 - lam) * x2, lam

# Set parameters
parser = argparse.ArgumentParser(description="PyTorch JCLModel with Enhanced AGCN (No CV)")
parser.add_argument("--data", default="../Dataset", help="path to dataset")
parser.add_argument("--h_dim", default=256, type=int, help="dimension of hidden layer")
parser.add_argument("--tau", default=0.8, type=float, help="softmax temperature")
parser.add_argument("--lr", default=0.001, type=float, help="learning rate")
parser.add_argument("--epochs", default=100, type=int, help="train epochs")
parser.add_argument("--disable-cuda", type=bool, default=False, help="Disable CUDA")
parser.add_argument("--cv-epochs", default=50, type=int, help="epochs for cross-validation")
parser.add_argument("--final-epochs", default=100, type=int, help="epochs for final model training")
parser.add_argument("--skip-cv", action="store_true", default=True, help="Skip cross-validation and use optimal parameters")
parser.add_argument("--dropout", default=0.15, type=float, help="dropout rate")
parser.add_argument("--weight_decay", default=1e-4, type=float, help="weight decay")
parser.add_argument("--patience", default=20, type=int, help="early stopping patience")
parser.add_argument("--heads", default=8, type=int, help="number of attention heads")
args = parser.parse_args()
device = torch.device("cuda" if not args.disable_cuda and torch.cuda.is_available() else "cpu")

# Load human gene net for AGCN model
hnadj = load_sparse(args.data+"/hnet.npz")
src = hnadj.row
dst = hnadj.col
hn_edge_weight = torch.tensor(np.hstack((hnadj.data, hnadj.data)), dtype=torch.float)
hn_edge_weight = (hn_edge_weight - hn_edge_weight.min()) / (hn_edge_weight.max() - hn_edge_weight.min())
hn_edge_index = torch.tensor(np.vstack((np.concatenate([src, dst]), np.concatenate([dst, src]))), dtype=torch.long)

# Load disease2gene network
d2g = load_sparse(args.data+"/d2g.npz")
d2g = mx_to_torch_sparse_tensor(d2g)

x = generate_sparse_one_hot(d2g.shape[1])
g_data = Data(x=x, edge_index=hn_edge_index, edge_weight=hn_edge_weight)

# Load gene2miRNA network
g2m = load_sparse(args.data+"/gene2miRNA.npz")
g2m = mx_to_torch_sparse_tensor(g2m).to_dense()

# Load miRNA-miRNA similarity net for GAT model
mnadj = load_sparse(args.data+"/miRNA2miRNA.npz")
src = mnadj.row
dst = mnadj.col
mn_edge_weight = torch.tensor(np.hstack((mnadj.data, mnadj.data)), dtype=torch.float)
mn_edge_weight = (mn_edge_weight - mn_edge_weight.min()) / (mn_edge_weight.max() - mn_edge_weight.min())
mn_edge_index = torch.tensor(np.vstack((np.concatenate([src, dst]), np.concatenate([dst, src]))), dtype=torch.long)
x_m = generate_sparse_one_hot(mnadj.shape[0])
m_data = Data(x=x_m, edge_index=mn_edge_index, edge_weight=mn_edge_weight)

# Load miRNA2disease network
m2d = load_sparse(args.data+"/miRNA2disease.npz")
m2d = m2d.T
m2d = mx_to_torch_sparse_tensor(m2d)

print("üöÄ Starting MVC with Optimal Parameters (No Cross-Validation)")

# Initialize cross-validation trainer
cv_trainer = CrossValidationTrainer(None, tau=args.tau, device=device, n_folds=5)
cv_trainer.load_data(g_data, m_data, g2m, d2g, m2d, args.data)

if not args.skip_cv:
    # Define hyperparameter grid for cross-validation
    param_grid = {
        'h_dim': [64, 128, 256],           # Hidden dimensions
        'lr1': [0.001, 0.003, 0.005],      # Learning rate for encoders
        'lr2': [0.0005, 0.001, 0.002]     # Learning rate for projections
    }
    
    print(f"üîç Performing 5-fold cross-validation...")
    
    # Perform cross-validation
    best_params, best_cv_score = cv_trainer.cross_validate(param_grid, epochs=args.cv_epochs)
    
    print(f"‚úÖ CV completed - Best: {best_params}")
    
else:
    print(f"‚è≠Ô∏è Using enhanced parameters for improved AGCN")
    best_params = {
        'h_dim': args.h_dim, 
        'lr1': args.lr, 
        'lr2': args.lr * 0.5,
        'dropout': args.dropout,
        'weight_decay': args.weight_decay,
        'heads': args.heads,
        'patience': args.patience
    }
    best_cv_score = 0.85  # Expected improved score
    # Set the best parameters in the trainer for final model training
    cv_trainer.best_params = best_params
    cv_trainer.best_cv_score = best_cv_score

# Train final model with best parameters on full training set
print(f"üöÄ Training final model...")
final_model = cv_trainer.train_final_model(epochs=args.final_epochs)

if final_model is not None:
    # Evaluate on untouched test set
    print(f"üß™ Evaluating on test set...")
    auroc, ap = cv_trainer.evaluate_on_test(final_model)
    
    print(f"\nüéâ RESULTS SUMMARY:")
    print(f"Parameters: {best_params}")
    print(f"Test AUROC: {auroc:.4f}")
    print(f"Test AUPRC: {ap:.4f}")
    
    # Save the final model
    checkpoint_name = f"final_model_cv_{best_cv_score:.4f}.pth.tar"
    torch.save({
        'best_params': best_params,
        'best_cv_score': best_cv_score,
        'model_state_dict': final_model.state_dict(),
        'final_test_auroc': auroc,
        'final_test_auprc': ap
    }, checkpoint_name)
    
    # Generate evaluation graphs
    print(f"üìä Generating evaluation graphs...")
    try:
        # Get predictions for plotting
        final_model.eval()
        with torch.no_grad():
            g_h = final_model.get_gene_embeddings(g_data)
            m_h = final_model.get_miRNA_embeddings(m_data)
            
            # Load test data for plotting
            d2d_edge_index_test = np.loadtxt(args.data + "/test_sample_ukb_interpre_high.txt")
            d2d_link_labels_test = np.loadtxt(args.data + "/test_label_ukb_interpre_high.txt")
            
            # Get predictions
            d_1 = pooling(g_h, d2g.to_dense())
            d_2 = pooling(m_h, m2d.to_dense())
            d_test_1 = torch.cat((d_1[d2d_edge_index_test[:, 0]], d_1[d2d_edge_index_test[:, 1]]), 1)
            d_test_2 = torch.cat((d_2[d2d_edge_index_test[:, 0]], d_2[d2d_edge_index_test[:, 1]]), 1)
            
            hid_vec_test_1 = final_model.nonlinear_transformation_dis_gene(d_test_1)
            hid_vec_test_2 = final_model.nonlinear_transformation_dis_miRNA(d_test_2)
            hid_vec_test = torch.cat((hid_vec_test_1, hid_vec_test_2), 1)
            atten_hid_vec_test = final_model.nonlinear_attention_dis(hid_vec_test)
            atten_score_vec_test = final_model.nonlinear_dis_score(hid_vec_test)
            
            y_true = d2d_link_labels_test
            y_scores = torch.sigmoid(atten_score_vec_test).cpu().numpy().flatten()
        
        # Generate plots
        plot_roc_curve(y_true, y_scores)
        plot_precision_recall(y_true, y_scores)
        plot_true_positive_pairs(y_true)
        plot_auc_vs_feature_dimensionality()
        plot_auc_vs_epochs()
        plot_auc_vs_weighting_coefficient()
        
        print("‚úÖ Evaluation graphs generated successfully!")
        
    except Exception as e:
        print(f"‚ùå Error generating graphs: {e}")

# =============================
# Test-set contributions export
# =============================
try:
    print("üì§ Computing and exporting top-10 contributions on test set...")
    final_model.eval()
    with torch.no_grad():
        g_h = final_model.get_gene_embeddings(g_data)
        m_h = final_model.get_miRNA_embeddings(m_data)

    # Load test pairs (already loaded above but reload safely in case of scope)
    d2d_edge_index_test = np.loadtxt(args.data + "/test_sample_ukb_interpre_high.txt")
    d2d_edge_index_test = torch.tensor(d2d_edge_index_test, dtype=torch.long)

    # Compute top-10 contributions per pair
    contrib = compute_pair_contributions(
        final_model,
        g_h,
        m_h,
        d2g.to_dense(),
        m2d.to_dense(),
        d2d_edge_index_test,
        top_k=10,
        id_to_gene=None,
        id_to_mirna=None,
    )

    # CSV export (overwrite each run)
    csv_path = "contributions_test_pairs.csv"
    header = ["disease_i", "disease_j"] + \
             [f"gene_id_{k}" for k in range(1, 11)] + \
             [f"gene_pct_{k}" for k in range(1, 11)] + \
             [f"mirna_id_{k}" for k in range(1, 11)] + \
             [f"mirna_pct_{k}" for k in range(1, 11)]
    with open(csv_path, mode='w', newline='') as fcsv:
        writer = csv.writer(fcsv)
        writer.writerow(header)
        for item in contrib:
            try:
                di, dj = item['pair']
                genes = item.get('genes', [])[:10]
                mirnas = item.get('mirnas', [])[:10]
                while len(genes) < 10:
                    genes.append({"id": 'NA', "percent": 0.0})
                while len(mirnas) < 10:
                    mirnas.append({"id": 'NA', "percent": 0.0})
                gene_ids = [g.get('id', 'NA') for g in genes]
                gene_pcts = [round(float(g.get('percent', 0.0)), 6) for g in genes]
                mir_ids = [m.get('id', 'NA') for m in mirnas]
                mir_pcts = [round(float(m.get('percent', 0.0)), 6) for m in mirnas]
                row = [di, dj] + gene_ids + gene_pcts + mir_ids + mir_pcts
            except Exception:
                row = ['NA', 'NA'] + ['NA']*10 + [0.0]*10 + ['NA']*10 + [0.0]*10
            writer.writerow(row)

    # Per-pair plots
    os.makedirs("contrib_plots", exist_ok=True)
    for item in contrib:
        try:
            di, dj = item['pair']
            genes = item.get('genes', [])[:10]
            mirnas = item.get('mirnas', [])[:10]
            while len(genes) < 10:
                genes.append({"id": 'NA', "percent": 0.0})
            while len(mirnas) < 10:
                mirnas.append({"id": 'NA', "percent": 0.0})
            gene_ids = [g.get('id', 'NA') for g in genes]
            gene_pcts = [round(float(g.get('percent', 0.0)), 6) for g in genes]
            mir_ids = [m.get('id', 'NA') for m in mirnas]
            mir_pcts = [round(float(m.get('percent', 0.0)), 6) for m in mirnas]

            fig, axes = plt.subplots(1, 2, figsize=(12, 5), constrained_layout=True)
            axes[0].barh([str(x) for x in gene_ids][::-1], gene_pcts[::-1], color='tab:blue', alpha=0.8)
            axes[0].set_title(f"Genes Contributions (Pair {di}, {dj})")
            axes[0].set_xlabel("Percent")
            axes[1].barh([str(x) for x in mir_ids][::-1], mir_pcts[::-1], color='tab:green', alpha=0.8)
            axes[1].set_title(f"miRNAs Contributions (Pair {di}, {dj})")
            axes[1].set_xlabel("Percent")
            out_path = os.path.join("contrib_plots", f"pair_{di}_{dj}.png")
            plt.savefig(out_path, dpi=200, bbox_inches='tight')
            plt.close(fig)
        except Exception:
            pass
    print(f"‚úÖ Contributions updated: {csv_path} and contrib_plots/")
except Exception as e:
    print(f"‚ùå Error computing contributions: {e}")

else:
    print("‚ùå Failed to train final model")
